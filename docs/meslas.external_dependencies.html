

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>meslas.external_dependencies package &mdash; MESLAS 0.1 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> MESLAS
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Main Modules:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="grid.html">Gridding Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="sampling.html">Gaussian Random Field Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="sensor.html">sampling module</a></li>
<li class="toctree-l1"><a class="reference internal" href="means.html">means module</a></li>
<li class="toctree-l1"><a class="reference internal" href="excursion.html">excursion module</a></li>
<li class="toctree-l1"><a class="reference internal" href="plotting.html">Plotting module</a></li>
</ul>
<p class="caption"><span class="caption-text">Advanced Usage</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="philosophy.html">Philosophy of the MESLAS package</a></li>
<li class="toctree-l1"><a class="reference internal" href="plotting.html">Plotting module</a></li>
<li class="toctree-l1"><a class="reference internal" href="grid.html">Gridding Module</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MESLAS</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>meslas.external_dependencies package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/meslas.external_dependencies.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="meslas-external-dependencies-package">
<h1>meslas.external_dependencies package<a class="headerlink" href="#meslas-external-dependencies-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-meslas.external_dependencies.numpytorch">
<span id="meslas-external-dependencies-numpytorch-module"></span><h2>meslas.external_dependencies.numpytorch module<a class="headerlink" href="#module-meslas.external_dependencies.numpytorch" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="meslas.external_dependencies.numpytorch.WrapTorch">
<em class="property">class </em><code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">WrapTorch</code><a class="headerlink" href="#meslas.external_dependencies.numpytorch.WrapTorch" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Uses torch as the backend; allows numpy-style sytax</p>
<dl class="field-list simple">
<dt class="field-odd">Attributes</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>newaxis</strong></dt><dd></dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#meslas.external_dependencies.numpytorch.WrapTorch.arange" title="meslas.external_dependencies.numpytorch.WrapTorch.arange"><code class="xref py py-obj docutils literal notranslate"><span class="pre">arange</span></code></a>()</p></td>
<td><p>Returns a 1-D tensor of size <span class="math notranslate nohighlight">\(\left\lceil \frac{\text{end} - \text{start}}{\text{step}} \right\rceil\)</span> with values from the interval <code class="docutils literal notranslate"><span class="pre">[start,</span> <span class="pre">end)</span></code> taken with common difference <code class="xref py py-attr docutils literal notranslate"><span class="pre">step</span></code> beginning from <cite>start</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#meslas.external_dependencies.numpytorch.WrapTorch.array" title="meslas.external_dependencies.numpytorch.WrapTorch.array"><code class="xref py py-obj docutils literal notranslate"><span class="pre">array</span></code></a>()</p></td>
<td><p>tensor(data, dtype=None, device=None, requires_grad=False, pin_memory=False) -&gt; Tensor</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#meslas.external_dependencies.numpytorch.WrapTorch.cat" title="meslas.external_dependencies.numpytorch.WrapTorch.cat"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cat</span></code></a>()</p></td>
<td><p>Concatenates the given sequence of <code class="xref py py-attr docutils literal notranslate"><span class="pre">seq</span></code> tensors in the given dimension.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#meslas.external_dependencies.numpytorch.WrapTorch.exp" title="meslas.external_dependencies.numpytorch.WrapTorch.exp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">exp</span></code></a>()</p></td>
<td><p>Returns a new tensor with the exponential of the elements of the input tensor <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#meslas.external_dependencies.numpytorch.WrapTorch.log" title="meslas.external_dependencies.numpytorch.WrapTorch.log"><code class="xref py py-obj docutils literal notranslate"><span class="pre">log</span></code></a>()</p></td>
<td><p>Returns a new tensor with the natural logarithm of the elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>abs</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>argmax</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>argmin</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>max</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>min</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>ones</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>sum</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>sumto1</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>zeros</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="meslas.external_dependencies.numpytorch.WrapTorch.abs">
<code class="sig-name descname">abs</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">\*args</em>, <em class="sig-param">\*\*kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.WrapTorch.abs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="meslas.external_dependencies.numpytorch.WrapTorch.arange">
<code class="sig-name descname">arange</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.WrapTorch.arange" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a 1-D tensor of size <span class="math notranslate nohighlight">\(\left\lceil \frac{\text{end} - \text{start}}{\text{step}} \right\rceil\)</span>
with values from the interval <code class="docutils literal notranslate"><span class="pre">[start,</span> <span class="pre">end)</span></code> taken with common difference
<code class="xref py py-attr docutils literal notranslate"><span class="pre">step</span></code> beginning from <cite>start</cite>.</p>
<p>Note that non-integer <code class="xref py py-attr docutils literal notranslate"><span class="pre">step</span></code> is subject to floating point rounding errors when
comparing against <code class="xref py py-attr docutils literal notranslate"><span class="pre">end</span></code>; to avoid inconsistency, we advise adding a small epsilon to <code class="xref py py-attr docutils literal notranslate"><span class="pre">end</span></code>
in such cases.</p>
<div class="math notranslate nohighlight">
\[\text{out}_{{i+1}} = \text{out}_{i} + \text{step}\]</div>
<dl>
<dt>Args:</dt><dd><p>start (Number): the starting value for the set of points. Default: <code class="docutils literal notranslate"><span class="pre">0</span></code>.
end (Number): the ending value for the set of points
step (Number): the gap between each pair of adjacent points. Default: <code class="docutils literal notranslate"><span class="pre">1</span></code>.
out (Tensor, optional): the output tensor.
dtype (<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.dtype</span></code>, optional): the desired data type of returned tensor.</p>
<blockquote>
<div><p>Default: if <code class="docutils literal notranslate"><span class="pre">None</span></code>, uses a global default (see <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.set_default_tensor_type()</span></code>). If <cite>dtype</cite> is not given, infer the data type from the other input
arguments. If any of <cite>start</cite>, <cite>end</cite>, or <cite>stop</cite> are floating-point, the
<cite>dtype</cite> is inferred to be the default dtype, see
<code class="xref py py-meth docutils literal notranslate"><span class="pre">get_default_dtype()</span></code>. Otherwise, the <cite>dtype</cite> is inferred to
be <cite>torch.int64</cite>.</p>
</div></blockquote>
<dl class="simple">
<dt>layout (<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.layout</span></code>, optional): the desired layout of returned Tensor.</dt><dd><p>Default: <code class="docutils literal notranslate"><span class="pre">torch.strided</span></code>.</p>
</dd>
<dt>device (<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.device</span></code>, optional): the desired device of returned tensor.</dt><dd><p>Default: if <code class="docutils literal notranslate"><span class="pre">None</span></code>, uses the current device for the default tensor type
(see <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.set_default_tensor_type()</span></code>). <code class="xref py py-attr docutils literal notranslate"><span class="pre">device</span></code> will be the CPU
for CPU tensor types and the current CUDA device for CUDA tensor types.</p>
</dd>
<dt>requires_grad (bool, optional): If autograd should record operations on the</dt><dd><p>returned tensor. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="go">tensor([ 0,  1,  2,  3,  4])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="go">tensor([ 1,  2,  3])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="go">tensor([ 1.0000,  1.5000,  2.0000])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt id="meslas.external_dependencies.numpytorch.WrapTorch.argmax">
<code class="sig-name descname">argmax</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">v</em>, <em class="sig-param">\*args</em>, <em class="sig-param">\*\*kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.WrapTorch.argmax" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="meslas.external_dependencies.numpytorch.WrapTorch.argmin">
<code class="sig-name descname">argmin</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">v</em>, <em class="sig-param">\*args</em>, <em class="sig-param">\*\*kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.WrapTorch.argmin" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="meslas.external_dependencies.numpytorch.WrapTorch.array">
<code class="sig-name descname">array</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.WrapTorch.array" title="Permalink to this definition">¶</a></dt>
<dd><p>tensor(data, dtype=None, device=None, requires_grad=False, pin_memory=False) -&gt; Tensor</p>
<p>Constructs a tensor with <code class="xref py py-attr docutils literal notranslate"><span class="pre">data</span></code>.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.tensor()</span></code> always copies <code class="xref py py-attr docutils literal notranslate"><span class="pre">data</span></code>. If you have a Tensor
<code class="docutils literal notranslate"><span class="pre">data</span></code> and want to avoid a copy, use <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.Tensor.requires_grad_()</span></code>
or <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.Tensor.detach()</span></code>.
If you have a NumPy <code class="docutils literal notranslate"><span class="pre">ndarray</span></code> and want to avoid a copy, use
<code class="xref py py-func docutils literal notranslate"><span class="pre">torch.as_tensor()</span></code>.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When data is a tensor <cite>x</cite>, <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.tensor()</span></code> reads out ‘the data’ from whatever it is passed,
and constructs a leaf variable. Therefore <code class="docutils literal notranslate"><span class="pre">torch.tensor(x)</span></code> is equivalent to <code class="docutils literal notranslate"><span class="pre">x.clone().detach()</span></code>
and <code class="docutils literal notranslate"><span class="pre">torch.tensor(x,</span> <span class="pre">requires_grad=True)</span></code> is equivalent to <code class="docutils literal notranslate"><span class="pre">x.clone().detach().requires_grad_(True)</span></code>.
The equivalents using <code class="docutils literal notranslate"><span class="pre">clone()</span></code> and <code class="docutils literal notranslate"><span class="pre">detach()</span></code> are recommended.</p>
</div>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>data (array_like): Initial data for the tensor. Can be a list, tuple,</dt><dd><p>NumPy <code class="docutils literal notranslate"><span class="pre">ndarray</span></code>, scalar, and other types.</p>
</dd>
<dt>dtype (<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.dtype</span></code>, optional): the desired data type of returned tensor.</dt><dd><p>Default: if <code class="docutils literal notranslate"><span class="pre">None</span></code>, infers data type from <code class="xref py py-attr docutils literal notranslate"><span class="pre">data</span></code>.</p>
</dd>
<dt>device (<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.device</span></code>, optional): the desired device of returned tensor.</dt><dd><p>Default: if <code class="docutils literal notranslate"><span class="pre">None</span></code>, uses the current device for the default tensor type
(see <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.set_default_tensor_type()</span></code>). <code class="xref py py-attr docutils literal notranslate"><span class="pre">device</span></code> will be the CPU
for CPU tensor types and the current CUDA device for CUDA tensor types.</p>
</dd>
<dt>requires_grad (bool, optional): If autograd should record operations on the</dt><dd><p>returned tensor. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
</dd>
<dt>pin_memory (bool, optional): If set, returned tensor would be allocated in</dt><dd><p>the pinned memory. Works only for CPU tensors. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.2</span><span class="p">,</span> <span class="mf">3.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">4.9</span><span class="p">,</span> <span class="mf">5.2</span><span class="p">]])</span>
<span class="go">tensor([[ 0.1000,  1.2000],</span>
<span class="go">        [ 2.2000,  3.1000],</span>
<span class="go">        [ 4.9000,  5.2000]])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>  <span class="c1"># Type inference on data</span>
<span class="go">tensor([ 0,  1])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.11111</span><span class="p">,</span> <span class="mf">0.222222</span><span class="p">,</span> <span class="mf">0.3333333</span><span class="p">]],</span>
<span class="go">                 dtype=torch.float64,</span>
<span class="go">                 device=torch.device(&#39;cuda:0&#39;))  # creates a torch.cuda.DoubleTensor</span>
<span class="go">tensor([[ 0.1111,  0.2222,  0.3333]], dtype=torch.float64, device=&#39;cuda:0&#39;)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">3.14159</span><span class="p">)</span>  <span class="c1"># Create a scalar (zero-dimensional tensor)</span>
<span class="go">tensor(3.1416)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([])</span>  <span class="c1"># Create an empty tensor (of size (0,))</span>
<span class="go">tensor([])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py attribute">
<dt id="meslas.external_dependencies.numpytorch.WrapTorch.backend">
<code class="sig-name descname">backend</code><em class="property"> = &lt;module 'torch' from '/home/cedric/anaconda3/envs/meslas/lib/python3.7/site-packages/torch/__init__.py'&gt;</em><a class="headerlink" href="#meslas.external_dependencies.numpytorch.WrapTorch.backend" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="meslas.external_dependencies.numpytorch.WrapTorch.cat">
<code class="sig-name descname">cat</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.WrapTorch.cat" title="Permalink to this definition">¶</a></dt>
<dd><p>Concatenates the given sequence of <code class="xref py py-attr docutils literal notranslate"><span class="pre">seq</span></code> tensors in the given dimension.
All tensors must either have the same shape (except in the concatenating
dimension) or be empty.</p>
<p><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.cat()</span></code> can be seen as an inverse operation for <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.split()</span></code>
and <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.chunk()</span></code>.</p>
<p><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.cat()</span></code> can be best understood via examples.</p>
<dl>
<dt>Args:</dt><dd><dl class="simple">
<dt>tensors (sequence of Tensors): any python sequence of tensors of the same type.</dt><dd><p>Non-empty tensors provided must have the same shape, except in the
cat dimension.</p>
</dd>
</dl>
<p>dim (int, optional): the dimension over which the tensors are concatenated
out (Tensor, optional): the output tensor.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>
<span class="go">tensor([[ 0.6580, -1.0969, -0.4614],</span>
<span class="go">        [-0.1034, -0.5790,  0.1497]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
<span class="go">tensor([[ 0.6580, -1.0969, -0.4614],</span>
<span class="go">        [-0.1034, -0.5790,  0.1497],</span>
<span class="go">        [ 0.6580, -1.0969, -0.4614],</span>
<span class="go">        [-0.1034, -0.5790,  0.1497],</span>
<span class="go">        [ 0.6580, -1.0969, -0.4614],</span>
<span class="go">        [-0.1034, -0.5790,  0.1497]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
<span class="go">tensor([[ 0.6580, -1.0969, -0.4614,  0.6580, -1.0969, -0.4614,  0.6580,</span>
<span class="go">         -1.0969, -0.4614],</span>
<span class="go">        [-0.1034, -0.5790,  0.1497, -0.1034, -0.5790,  0.1497, -0.1034,</span>
<span class="go">         -0.5790,  0.1497]])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt id="meslas.external_dependencies.numpytorch.WrapTorch.exp">
<code class="sig-name descname">exp</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.WrapTorch.exp" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new tensor with the exponential of the elements
of the input tensor <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p>
<div class="math notranslate nohighlight">
\[y_{i} = e^{x_{i}}\]</div>
<dl class="simple">
<dt>Args:</dt><dd><p>input (Tensor): the input tensor.
out (Tensor, optional): the output tensor.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">2.</span><span class="p">)]))</span>
<span class="go">tensor([ 1.,  2.])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt id="meslas.external_dependencies.numpytorch.WrapTorch.log">
<code class="sig-name descname">log</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.WrapTorch.log" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new tensor with the natural logarithm of the elements
of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p>
<div class="math notranslate nohighlight">
\[y_{i} = \log_{e} (x_{i})\]</div>
<dl class="simple">
<dt>Args:</dt><dd><p>input (Tensor): the input tensor.
out (Tensor, optional): the output tensor.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">tensor([-0.7168, -0.5471, -0.8933, -1.4428, -0.1190])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">tensor([ nan,  nan,  nan,  nan,  nan])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt id="meslas.external_dependencies.numpytorch.WrapTorch.max">
<code class="sig-name descname">max</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">v</em>, <em class="sig-param">\*args</em>, <em class="sig-param">\*\*kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.WrapTorch.max" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="meslas.external_dependencies.numpytorch.WrapTorch.min">
<code class="sig-name descname">min</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">v</em>, <em class="sig-param">\*args</em>, <em class="sig-param">\*\*kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.WrapTorch.min" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="meslas.external_dependencies.numpytorch.WrapTorch.newaxis">
<code class="sig-name descname">newaxis</code><em class="property"> = None</em><a class="headerlink" href="#meslas.external_dependencies.numpytorch.WrapTorch.newaxis" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="meslas.external_dependencies.numpytorch.WrapTorch.ones">
<code class="sig-name descname">ones</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">\*args</em>, <em class="sig-param">\*\*kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.WrapTorch.ones" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="meslas.external_dependencies.numpytorch.WrapTorch.sum">
<code class="sig-name descname">sum</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">v</em>, <em class="sig-param">\*args</em>, <em class="sig-param">\*\*kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.WrapTorch.sum" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="meslas.external_dependencies.numpytorch.WrapTorch.sumto1">
<code class="sig-name descname">sumto1</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">v</span></em>, <em class="sig-param"><span class="n">dim</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.WrapTorch.sumto1" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="meslas.external_dependencies.numpytorch.WrapTorch.zeros">
<code class="sig-name descname">zeros</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">\*args</em>, <em class="sig-param">\*\*kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.WrapTorch.zeros" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.aggregate">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">aggregate</code><span class="sig-paren">(</span><em class="sig-param">subs</em>, <em class="sig-param">val=1.0</em>, <em class="sig-param">\*args</em>, <em class="sig-param">\*\*kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.aggregate" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>subs</strong> (torch.LongTensor, (<a href="#id1"><span class="problematic" id="id2">*</span></a>torch.LongTensor)) – [dim, element]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.append_dim">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">append_dim</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">v</span></em>, <em class="sig-param"><span class="n">n_dim_to_append</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.append_dim" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.append_to_ndim">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">append_to_ndim</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">v</span></em>, <em class="sig-param"><span class="n">n_dim_desired</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.append_to_ndim" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.attach_dim">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">attach_dim</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">v</span></em>, <em class="sig-param"><span class="n">n_dim_to_prepend</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">n_dim_to_append</span><span class="o">=</span><span class="default_value">0</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.attach_dim" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.block_diag">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">block_diag</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">m</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.block_diag" title="Permalink to this definition">¶</a></dt>
<dd><p>Make a block diagonal matrix along dim=-3
EXAMPLE:
block_diag(torch.ones(4,3,2))
should give a 12 x 8 matrix with blocks of 3 x 2 ones.
Prepend batch dimensions if needed.
You can also give a list of matrices.
:type m: torch.Tensor, list
:rtype: torch.Tensor</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.block_diag_irregular">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">block_diag_irregular</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">matrices</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.block_diag_irregular" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.bootstrap">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">bootstrap</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">fun</span></em>, <em class="sig-param"><span class="n">samp</span></em>, <em class="sig-param"><span class="n">n_boot</span><span class="o">=</span><span class="default_value">100</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.bootstrap" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.categrnd">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">categrnd</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">probs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">logits</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">sample_shape</span><span class="o">=</span><span class="default_value">()</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.categrnd" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.circdiff">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">circdiff</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">angle1</span></em>, <em class="sig-param"><span class="n">angle2</span></em>, <em class="sig-param"><span class="n">maxangle</span><span class="o">=</span><span class="default_value">tensor(6.2832)</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.circdiff" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>angle1</strong> – angle scaled to be between 0 and maxangle</p></li>
<li><p><strong>angle2</strong> – angle scaled to be between 0 and maxangle</p></li>
<li><p><strong>maxangle</strong> – max angle. defaults to 2 * pi.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>angular difference, between -.5 and +.5 * maxangle</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.conv_t">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">conv_t</code><span class="sig-paren">(</span><em class="sig-param">p</em>, <em class="sig-param">kernel</em>, <em class="sig-param">\*\*kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.conv_t" title="Permalink to this definition">¶</a></dt>
<dd><p>1D convolution with the starting time of the signal and kernel anchored.</p>
<p>EXAMPLE:
p_cond_rt = npt.conv_t(</p>
<blockquote>
<div><p>p_cond_td[None],  # [1, cond, fr]
p_tnd[None, None, :].expand([n_cond, 1, nt]), # [cond, 1, fr]
groups=n_cond</p>
</div></blockquote>
<p>)
:param p: [batch, time] or [batch, channel_in, time]
:param kernel: [time] or [channel_out, channel_in, time]
:param kwargs: fed to F.conv1d
:return: p[batch, time] or [batch, channel_out, time]</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.crossvalincl">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">crossvalincl</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">n_tr</span></em>, <em class="sig-param"><span class="n">i_fold</span></em>, <em class="sig-param"><span class="n">n_fold</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">mode</span><span class="o">=</span><span class="default_value">'consec'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.crossvalincl" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_tr</strong> – Number of trials</p></li>
<li><p><strong>i_fold</strong> – Index of fold</p></li>
<li><p><strong>n_fold</strong> – Number of folds. If 1, training set = test set.</p></li>
<li><p><strong>mode</strong> – ‘consec’: consecutive trials; ‘mod’: interleaved</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>boolean (Byte) tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.deg2rad">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">deg2rad</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">deg</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.deg2rad" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.delta">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">delta</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">levels</span></em>, <em class="sig-param"><span class="n">v</span></em>, <em class="sig-param"><span class="n">dlevel</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.delta" title="Permalink to this definition">¶</a></dt>
<dd><p>&#64;type levels: torch.Tensor
&#64;type v: torch.Tensor
&#64;type dlevel: torch.Tensor
&#64;rtype: torch.Tensor</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.enforce_tensor">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">enforce_tensor</code><span class="sig-paren">(</span><em class="sig-param">v: Union[float, numpy.ndarray, torch.Tensor], min_ndim=1, \*\*kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.enforce_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct a tensor if the input is not; otherwise return the input as is.
Same as enforce_tensor
:param v:
:param min_ndim:
:param kwargs:
:return:</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.entropy">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">entropy</code><span class="sig-paren">(</span><em class="sig-param">tensor</em>, <em class="sig-param">\*args</em>, <em class="sig-param">\*\*kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.entropy" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tensor</strong> (<em>torch.Tensor</em>) – probability. Optionally provide dim and keepdim for</p>
</dd>
</dl>
<p>summation.
:return: torch.Tensor</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.expand_all">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">expand_all</code><span class="sig-paren">(</span><em class="sig-param">\*args</em>, <em class="sig-param">shape=None</em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.expand_all" title="Permalink to this definition">¶</a></dt>
<dd><p>Expand tensors so that all tensors are of the same size.
Tensors must have the same number of dimensions;
otherwise, use expand_batch() to prepend dimensions.
:param args:
:param shape:
:return:</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.expand_batch">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">expand_batch</code><span class="sig-paren">(</span><em class="sig-param">\*args</em>, <em class="sig-param">\*\*kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.expand_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Same as repeat_batch except forcing use_expand=True, to share memory
across repeats, i.e., expand first dimensions, while keeping last
dimensions the same
:param args: tuple of tensors to repeat.
:param repeat_existing_dims: whether to repeat singleton dims.
:param to_append_dims: if True, append dims if needed; if False, prepend.
:param shape: desired shape of the output. Give None to match max shape
of each dim. Give -1 at dims where the max shape is desired.
:return: tuple of repeated tensors.</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.expand_upto_dim">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">expand_upto_dim</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">args</span></em>, <em class="sig-param"><span class="n">dim</span></em>, <em class="sig-param"><span class="n">to_expand_left</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.expand_upto_dim" title="Permalink to this definition">¶</a></dt>
<dd><p>Similar to expand_batch(), but keeps some dims unexpanded even if they
don’t match.
:param args: iterable yielding torch.Tensor
:param dim: if to_expand_left=True, then arg[:dim] is expanded,</p>
<blockquote>
<div><p>otherwise, arg[dim:] is expanded, for each arg in args.
Note that dim=-1 leaves the last dim unexpanded.
This is necessary to make dim=0 expand the first.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>to_expand_left</strong> – if True, left of dim is expanded while the rest of</p>
</dd>
</dl>
<p>the dims are kept unchanged.
:return: tuple of expanded args</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.float">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">float</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">v</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.float" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.freeze">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">freeze</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">module</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.freeze" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.get_jacobian">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">get_jacobian</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">net</span></em>, <em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">noutputs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.get_jacobian" title="Permalink to this definition">¶</a></dt>
<dd><p>From <a class="reference external" href="https://gist.github.com/sbarratt/37356c46ad1350d4c30aefbd488a4faa">https://gist.github.com/sbarratt/37356c46ad1350d4c30aefbd488a4faa</a>
:type net: torch.nn.Module
:type x: torch.Tensor
:type noutputs: int
:rtype: torch.Tensor</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.interp1d">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">interp1d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">query</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">value</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">dim</span><span class="o">=</span><span class="default_value">0</span></em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="headerlink" href="#meslas.external_dependencies.numpytorch.interp1d" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>query</strong> – index on dim. Should be a FloatTensor for gradient.</p></li>
<li><p><strong>value</strong> – </p></li>
<li><p><strong>dim</strong> – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>interpolated to give value[query] (when dim=0)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.inv_gaussian_cdf">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">inv_gaussian_cdf</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">mu</span></em>, <em class="sig-param"><span class="n">lam</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.inv_gaussian_cdf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.inv_gaussian_mean_std2params">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">inv_gaussian_mean_std2params</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">mu</span></em>, <em class="sig-param"><span class="n">std</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.inv_gaussian_mean_std2params" title="Permalink to this definition">¶</a></dt>
<dd><p>mu, std -&gt; mu, lam</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.inv_gaussian_pdf">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">inv_gaussian_pdf</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">mu</span></em>, <em class="sig-param"><span class="n">lam</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.inv_gaussian_pdf" title="Permalink to this definition">¶</a></dt>
<dd><p>As in <a class="reference external" href="https://en.wikipedia.org/wiki/Inverse_Gaussian_distribution">https://en.wikipedia.org/wiki/Inverse_Gaussian_distribution</a>
&#64;param x: values to query. Must be positive.
&#64;param mu: the expectation
&#64;param lam: lambda in Wikipedia’s notation
&#64;return: p(x; mu, lam)</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.inv_gaussian_pmf_mean_stdev">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">inv_gaussian_pmf_mean_stdev</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">mu</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">std</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">dx</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">algo</span><span class="o">=</span><span class="default_value">'diff_cdf'</span></em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="headerlink" href="#meslas.external_dependencies.numpytorch.inv_gaussian_pmf_mean_stdev" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – must be a 1-dim tensor along dim.</p></li>
<li><p><strong>mu</strong> – </p></li>
<li><p><strong>std</strong> – </p></li>
<li><p><strong>dx</strong> – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.inv_gaussian_variance">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">inv_gaussian_variance</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">mu</span></em>, <em class="sig-param"><span class="n">lam</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.inv_gaussian_variance" title="Permalink to this definition">¶</a></dt>
<dd><p>As in <a class="reference external" href="https://en.wikipedia.org/wiki/Inverse_Gaussian_distribution">https://en.wikipedia.org/wiki/Inverse_Gaussian_distribution</a>
&#64;param mu: the expectation
&#64;param lam: lambda in Wikipedia’s notation
&#64;return: Var[X]</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.inv_gaussian_variance2lam">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">inv_gaussian_variance2lam</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">mu</span></em>, <em class="sig-param"><span class="n">var</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.inv_gaussian_variance2lam" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.isnan">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">isnan</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">v</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.isnan" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.kron">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">kron</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.kron" title="Permalink to this definition">¶</a></dt>
<dd><p>Kronecker product of matrices a and b with leading batch dimensions.
Batch dimensions are broadcast. The number of them mush
:type a: torch.Tensor
:type b: torch.Tensor
:rtype: torch.Tensor</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.kw_np2torch">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">kw_np2torch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">kw</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.kw_np2torch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.log_normpdf">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">log_normpdf</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sample</span></em>, <em class="sig-param"><span class="n">mu</span><span class="o">=</span><span class="default_value">0.0</span></em>, <em class="sig-param"><span class="n">sigma</span><span class="o">=</span><span class="default_value">1.0</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.log_normpdf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.logistic">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">logistic</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span><span class="p">:</span> <span class="n">torch.Tensor</span></em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="headerlink" href="#meslas.external_dependencies.numpytorch.logistic" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.logit">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">logit</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p</span><span class="p">:</span> <span class="n">torch.Tensor</span></em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="headerlink" href="#meslas.external_dependencies.numpytorch.logit" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.lognorm_params_given_mean_stdev">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">lognorm_params_given_mean_stdev</code><span class="sig-paren">(</span><em class="sig-param">mean: torch.Tensor</em>, <em class="sig-param">stdev: torch.Tensor) -&gt; (&lt;class 'torch.Tensor'&gt;</em>, <em class="sig-param">&lt;class 'torch.Tensor'&gt;</em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.lognorm_params_given_mean_stdev" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.lognorm_pmf">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">lognorm_pmf</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">mean</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">stdev</span><span class="p">:</span> <span class="n">torch.Tensor</span></em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="headerlink" href="#meslas.external_dependencies.numpytorch.lognorm_pmf" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – must be monotonic increasing with equal increment on dim 0</p></li>
<li><p><strong>mean</strong> – </p></li>
<li><p><strong>stdev</strong> – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>p[k] = P(x[k] &lt; X &lt; x[k + 1]; mean, stdev)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.lognormal_params2mean_stdev">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">lognormal_params2mean_stdev</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">loc</span></em>, <em class="sig-param"><span class="n">scale</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.lognormal_params2mean_stdev" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.m2v">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">m2v</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">mm</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.m2v" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.m2v0">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">m2v0</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">mat</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.m2v0" title="Permalink to this definition">¶</a></dt>
<dd><p>Matrix dims come first, unlike v2m</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.mat2vec0">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">mat2vec0</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">mat</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.mat2vec0" title="Permalink to this definition">¶</a></dt>
<dd><p>Matrix dims come first, unlike v2m</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.matmul0">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">matmul0</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.matmul0" title="Permalink to this definition">¶</a></dt>
<dd><p>Matrix dims come first, unlike torch.matmul</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.matmul2vec">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">matmul2vec</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">mm</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.matmul2vec" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.matsum">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">matsum</code><span class="sig-paren">(</span><em class="sig-param">\*tensors</em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.matsum" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply expand_upto_dim(tensors, -2) before adding them together,
consistent with torch.matmul()
:param tensors: iterable of tensors
:return: sum of tensors, expanded except for the last two dimensions.</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.matvecmul0">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">matvecmul0</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">mat</span></em>, <em class="sig-param"><span class="n">vec</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.matvecmul0" title="Permalink to this definition">¶</a></dt>
<dd><p>Matrix and vec dims come first. Vec is expanded to mat first.</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.max_distrib">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">max_distrib</code><span class="sig-paren">(</span><em class="sig-param">p: torch.Tensor) -&gt; (&lt;class 'torch.Tensor'&gt;</em>, <em class="sig-param">&lt;class 'torch.Tensor'&gt;</em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.max_distrib" title="Permalink to this definition">¶</a></dt>
<dd><p>Distribution of the max of independent RVs R0 ~ p[0] and R1 ~ p[1].
When ndims(p) &gt; 2, each pair of p[0, r0, :] and p[1, r1, :] is processed
separately. p.sum(1) is taken as the number of trials.</p>
<p>p_max, p_1st = min_distrib(p)</p>
<p>p_max(t,1,:): Probability distribution of min(t_1 ~ p(:,1), t_2 ~ p(:,2))
p_last(t,k,:): Probability of t_k happening first at t.</p>
<blockquote>
<div><p>sums(p_1st, [1, 2]) gives all 1’s.</p>
</div></blockquote>
<p>Formula from: <a class="reference external" href="http://math.stackexchange.com/questions/308230/expectation-of-the-min-of-two-independent-random-variables">http://math.stackexchange.com/questions/308230/expectation-of-the-min-of-two-independent-random-variables</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>p</strong> – [id, value, [batch, …]]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>p_max[value, batch, …], p_last[id, value, batch, …]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.max_shape">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">max_shape</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">shapes</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.max_shape" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.mean_distrib">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">mean_distrib</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p</span></em>, <em class="sig-param"><span class="n">v</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.mean_distrib" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.min_distrib">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">min_distrib</code><span class="sig-paren">(</span><em class="sig-param">p: torch.Tensor) -&gt; (&lt;class 'torch.Tensor'&gt;</em>, <em class="sig-param">&lt;class 'torch.Tensor'&gt;</em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.min_distrib" title="Permalink to this definition">¶</a></dt>
<dd><p>Distribution of the min of independent RVs R0 ~ p[0] and R1 ~ p[1].
When ndims(p) &gt; 2, each pair of p[0, r0, :] and p[1, r1, :] is processed
separately. p.sum(1) is taken as the number of trials.</p>
<p>p_min, p_1st = min_distrib(p)</p>
<p>p_min(t,1,:): Probability distribution of min(t_1 ~ p(:,1), t_2 ~ p(:,2))
p_1st(t,k,:): Probability of t_k happening first at t.</p>
<blockquote>
<div><p>sums(p_1st, [1, 2]) gives all 1’s.</p>
</div></blockquote>
<p>Formula from: <a class="reference external" href="http://math.stackexchange.com/questions/308230/expectation-of-the-min-of-two-independent-random-variables">http://math.stackexchange.com/questions/308230/expectation-of-the-min-of-two-independent-random-variables</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>p</strong> – [id, value, [batch, …]]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>p_min[value, batch, …], p_1st[id, value, batch, …]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.mm0">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">mm0</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.mm0" title="Permalink to this definition">¶</a></dt>
<dd><p>Matrix dims come first, unlike torch.matmul</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.mvm0">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">mvm0</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">mat</span></em>, <em class="sig-param"><span class="n">vec</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.mvm0" title="Permalink to this definition">¶</a></dt>
<dd><p>Matrix and vec dims come first. Vec is expanded to mat first.</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.mvnpdf_log">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">mvnpdf_log</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">mu</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">sigma</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.mvnpdf_log" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – [batch, ndim]</p></li>
<li><p><strong>mu</strong> – [batch, ndim]</p></li>
<li><p><strong>sigma</strong> – [batch, ndim, ndim]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>log_prob [batch]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.FloatTensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.mvnrnd">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">mvnrnd</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">mu</span></em>, <em class="sig-param"><span class="n">sigma</span></em>, <em class="sig-param"><span class="n">sample_shape</span><span class="o">=</span><span class="default_value">()</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.mvnrnd" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.nan2v">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">nan2v</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">v</span></em>, <em class="sig-param"><span class="n">fill</span><span class="o">=</span><span class="default_value">0</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.nan2v" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.nanmean">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">nanmean</code><span class="sig-paren">(</span><em class="sig-param">v</em>, <em class="sig-param">\*args</em>, <em class="sig-param">inplace=False</em>, <em class="sig-param">\*\*kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.nanmean" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.nansum">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">nansum</code><span class="sig-paren">(</span><em class="sig-param">v</em>, <em class="sig-param">\*args</em>, <em class="sig-param">inplace=False</em>, <em class="sig-param">\*\*kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.nansum" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.normrnd">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">normrnd</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">mu</span><span class="o">=</span><span class="default_value">0.0</span></em>, <em class="sig-param"><span class="n">sigma</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="n">sample_shape</span><span class="o">=</span><span class="default_value">()</span></em>, <em class="sig-param"><span class="n">return_distrib</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.normrnd" title="Permalink to this definition">¶</a></dt>
<dd><p>&#64;param mu:
&#64;param sigma:
&#64;param sample_shape:
&#64;type return_distrib: bool
&#64;rtype: Union[(torch.Tensor, torch.distributions.Distribution),
torch.Tensor]</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.npy">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">npy</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">v</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>torch.Tensor<span class="p">, </span>numpy.ndarray<span class="p">]</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.npy" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct a np.ndarray from tensor; otherwise return the input as is
:type v: torch.Tensor
:rtype: np.ndarray</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.npys">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">npys</code><span class="sig-paren">(</span><em class="sig-param">\*args</em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.npys" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.numpy">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">numpy</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">v</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>torch.Tensor<span class="p">, </span>numpy.ndarray<span class="p">]</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.numpy" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct a np.ndarray from tensor; otherwise return the input as is
:type v: torch.Tensor
:rtype: np.ndarray</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.onehotrnd">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">onehotrnd</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">probs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">logits</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">sample_shape</span><span class="o">=</span><span class="default_value">()</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.onehotrnd" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.p2en">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">p2en</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">v</span></em>, <em class="sig-param"><span class="n">ndim_st</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.p2en" title="Permalink to this definition">¶</a></dt>
<dd><p>Permute first ndim_en of an array v to the last
:type v: torch.Tensor
:type ndim_st: int
:rtype: torch.Tensor</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.p2st">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">p2st</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">v</span></em>, <em class="sig-param"><span class="n">ndim_en</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.p2st" title="Permalink to this definition">¶</a></dt>
<dd><p>Permute last ndim_en of an array v to the first
:type v: torch.Tensor
:type ndim_en: int
:rtype: torch.Tensor</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.pconc2conc">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">pconc2conc</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">pconc</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.pconc2conc" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.permute2en">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">permute2en</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">v</span></em>, <em class="sig-param"><span class="n">ndim_st</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.permute2en" title="Permalink to this definition">¶</a></dt>
<dd><p>Permute first ndim_en of an array v to the last
:type v: torch.Tensor
:type ndim_st: int
:rtype: torch.Tensor</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.permute2st">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">permute2st</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">v</span></em>, <em class="sig-param"><span class="n">ndim_en</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.permute2st" title="Permalink to this definition">¶</a></dt>
<dd><p>Permute last ndim_en of an array v to the first
:type v: torch.Tensor
:type ndim_en: int
:rtype: torch.Tensor</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.prad2unitvec">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">prad2unitvec</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">prad</span></em>, <em class="sig-param"><span class="n">dim</span><span class="o">=</span><span class="default_value">- 1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.prad2unitvec" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.prepend_dim">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">prepend_dim</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">v</span></em>, <em class="sig-param"><span class="n">n_dim_to_prepend</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.prepend_dim" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.prepend_to_ndim">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">prepend_to_ndim</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">v</span></em>, <em class="sig-param"><span class="n">n_dim_desired</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.prepend_to_ndim" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.rad2deg">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">rad2deg</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">rad</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.rad2deg" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.rand">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">rand</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">shape</span></em>, <em class="sig-param"><span class="n">low</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">high</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.rand" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.ravel_multi_index">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">ravel_multi_index</code><span class="sig-paren">(</span><em class="sig-param">v</em>, <em class="sig-param">shape</em>, <em class="sig-param">\*\*kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.ravel_multi_index" title="Permalink to this definition">¶</a></dt>
<dd><p>For now, just use np.ravel_multi_index()
:type v: torch.LongTensor
:type shape: torch.Size, tuple, list
:type kwargs: dict
:return: torch.LongTensor</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.repeat_all">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">repeat_all</code><span class="sig-paren">(</span><em class="sig-param">\*args</em>, <em class="sig-param">shape=None</em>, <em class="sig-param">use_expand=False</em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.repeat_all" title="Permalink to this definition">¶</a></dt>
<dd><p>Repeat tensors so that all tensors are of the same size.
Tensors must have the same number of dimensions;
otherwise, use repeat_batch() to prepend dimensions.
:param shape: desired shape of the output. Give None to match max shape
of each dim. Give -1 at dims where the max shape is desired.</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.repeat_batch">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">repeat_batch</code><span class="sig-paren">(</span><em class="sig-param">\*args</em>, <em class="sig-param">repeat_existing_dims=False</em>, <em class="sig-param">to_append_dims=False</em>, <em class="sig-param">shape=None</em>, <em class="sig-param">use_expand=False</em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.repeat_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Repeat first dimensions, while keeping last dimensions the same.
:param args: tuple of tensors to repeat.
:param repeat_existing_dims: whether to repeat singleton dims.
:param to_append_dims: if True, append dims if needed; if False, prepend.
:param shape: desired shape of the output. Give None to match max shape
of each dim. Give -1 at dims where the max shape is desired.
:param use_expand: True to use torch.expand instead of torch.repeat,
to share the same memory across repeats.
:return: tuple of repeated tensors.</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.repeat_dim">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">repeat_dim</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">tensor</span></em>, <em class="sig-param"><span class="n">repeat</span></em>, <em class="sig-param"><span class="n">dim</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.repeat_dim" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
</dl>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.repeat_to_shape">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">repeat_to_shape</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">arg</span></em>, <em class="sig-param"><span class="n">shape</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.repeat_to_shape" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>shape</strong> – desired shape of the output</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.scatter_add">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">scatter_add</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">subs</span></em>, <em class="sig-param"><span class="n">val</span></em>, <em class="sig-param"><span class="n">dim</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">shape</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.scatter_add" title="Permalink to this definition">¶</a></dt>
<dd><p>&#64;param subs: ndim x n indices, suitable for np.ravel_multi_index
&#64;type subs: Union[np.ndarray, torch.LongTensor])
&#64;param val: n x … values to add
&#64;type val: torch.Tensor
&#64;return:</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.sem">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">sem</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">v</span></em>, <em class="sig-param"><span class="n">dim</span><span class="o">=</span><span class="default_value">0</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.sem" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.sem_distrib">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">sem_distrib</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p</span></em>, <em class="sig-param"><span class="n">v</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">n</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.sem_distrib" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.shiftdim">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">shiftdim</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">v</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">shift</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">dim</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">pad</span><span class="o">=</span><span class="default_value">'repeat'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.shiftdim" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.softmax_bias">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">softmax_bias</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p</span></em>, <em class="sig-param"><span class="n">slope</span></em>, <em class="sig-param"><span class="n">bias</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.softmax_bias" title="Permalink to this definition">¶</a></dt>
<dd><p>Symmetric softmax with bias. Only works for binary. Works elementwise.
Cannot use too small or large bias (roughly &lt; 1e-3 or &gt; 1 - 1e-3)
:param p: between 0 and 1.
:param slope: arbitary real value. 1 gives identity mapping, 0 always 0.5.
:param bias: between 1e-3 and 1 - 1e-3. Giving p=bias returns 0.5.
:return: transformed probability.
:type p: torch.FloatTensor
:type slope: torch.FloatTensor
:type bias: torch.FloatTensor
:rtype: torch.FloatTensor</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.softmax_mask">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">softmax_mask</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">w</span><span class="p">:</span> <span class="n">torch.Tensor</span></em>, <em class="sig-param"><span class="n">dim</span><span class="o">=</span><span class="default_value">- 1</span></em>, <em class="sig-param"><span class="n">mask</span><span class="p">:</span> <span class="n">torch.BoolTensor</span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="headerlink" href="#meslas.external_dependencies.numpytorch.softmax_mask" title="Permalink to this definition">¶</a></dt>
<dd><p>Allows having -np.inf in w to mask out, or give explicit bool mask
:param w:
:param dim:
:param mask:
:return:</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.std_distrib">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">std_distrib</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p</span></em>, <em class="sig-param"><span class="n">v</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.std_distrib" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.sumto1">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">sumto1</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">v</span></em>, <em class="sig-param"><span class="n">dim</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">keepdim</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.sumto1" title="Permalink to this definition">¶</a></dt>
<dd><p>Make v sum to 1 across dim, i.e., make dim conditioned on the rest.
dim can be a tuple.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>v</strong> – tensor.</p></li>
<li><p><strong>dim</strong> – dimensions to be conditioned upon the rest.</p></li>
<li><p><strong>axis</strong> – if given, overrides dim.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>tensor of the same shape as v.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.t">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">t</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">tensor</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.t" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.tensor">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">tensor</code><span class="sig-paren">(</span><em class="sig-param">v: Union[float, numpy.ndarray, torch.Tensor], min_ndim=1, \*\*kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct a tensor if the input is not; otherwise return the input as is.
Same as enforce_tensor
:param v:
:param min_ndim:
:param kwargs:
:return:</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.test_kron">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">test_kron</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.test_kron" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.test_softmax_bias">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">test_softmax_bias</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.test_softmax_bias" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.unblock_diag">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">unblock_diag</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">m</span></em>, <em class="sig-param"><span class="n">n</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">size_block</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.unblock_diag" title="Permalink to this definition">¶</a></dt>
<dd><p>The inverse of block_diag(). Not vectorized yet.
:param m: block diagonal matrix
:param n: int. Number of blocks
:size_block: torch.Size. Size of a block.
:return: tensor unblocked such that the last sizes are [n] + size_block</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.unravel_index">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">unravel_index</code><span class="sig-paren">(</span><em class="sig-param">v</em>, <em class="sig-param">shape</em>, <em class="sig-param">\*\*kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.unravel_index" title="Permalink to this definition">¶</a></dt>
<dd><p>For now, just use np.unravel_index()
:type v: torch.LongTensor
:type shape: torch.Size, tuple, list
:type kwargs: dict
:return: torch.LongTensor</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.v2m">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">v2m</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">vec</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.v2m" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.v2m0">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">v2m0</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">vec</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.v2m0" title="Permalink to this definition">¶</a></dt>
<dd><p>Vector dim comes first, unlike v2m</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.var_distrib">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">var_distrib</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p</span></em>, <em class="sig-param"><span class="n">v</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.var_distrib" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.vec2mat0">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">vec2mat0</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">vec</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.vec2mat0" title="Permalink to this definition">¶</a></dt>
<dd><p>Vector dim comes first, unlike v2m</p>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.vec2matmul">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">vec2matmul</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">vec</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.vec2matmul" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.vec_on">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">vec_on</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">v</span></em>, <em class="sig-param"><span class="n">dim</span></em>, <em class="sig-param"><span class="n">ndim</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.vec_on" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.vec_on_dim">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">vec_on_dim</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">v</span></em>, <em class="sig-param"><span class="n">dim</span></em>, <em class="sig-param"><span class="n">ndim</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.vec_on_dim" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.vmpdf">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">vmpdf</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">mu</span></em>, <em class="sig-param"><span class="n">scale</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">normalize</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.vmpdf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.vmpdf_a_given_b">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">vmpdf_a_given_b</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a_prad</span></em>, <em class="sig-param"><span class="n">b_prad</span></em>, <em class="sig-param"><span class="n">pconc</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.vmpdf_a_given_b" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a_prad</strong> (<em>torch.Tensor</em>) – between 0 and 1. Maps to 0 and 2*pi.</p></li>
<li><p><strong>b_prad</strong> (<em>torch.Tensor</em>) – between 0 and 1. Maps to 0 and 2*pi.</p></li>
<li><p><strong>pconc</strong> – float</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>p_a_given_b[index_a, index_b]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="meslas.external_dependencies.numpytorch.vmpdf_prad_pconc">
<code class="sig-prename descclassname">meslas.external_dependencies.numpytorch.</code><code class="sig-name descname">vmpdf_prad_pconc</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">prad</span></em>, <em class="sig-param"><span class="n">ploc</span></em>, <em class="sig-param"><span class="n">pconc</span></em>, <em class="sig-param"><span class="n">normalize</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#meslas.external_dependencies.numpytorch.vmpdf_prad_pconc" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prad</strong> – 0 to 1 maps to 0 to 2*pi radians</p></li>
<li><p><strong>pconc</strong> – 0 to 1 maps to 0 to inf concentration</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-meslas.external_dependencies">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-meslas.external_dependencies" title="Permalink to this headline">¶</a></h2>
</div>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Trygve Olav Fossum, Jo Eidsvik, David Ginsbourger, Kanna Rajan, Cedric Travelletti

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>